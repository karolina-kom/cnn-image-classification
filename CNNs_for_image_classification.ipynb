{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN2/1y9Nz1JA0GO9HeS00D6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karolina-kom/cnn-image-classification/blob/main/CNNs_for_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "p492htAp8EI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary libraries."
      ],
      "metadata": {
        "id": "iwFvIIpp8Mv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "u5tHV-s77v43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the dataset."
      ],
      "metadata": {
        "id": "uCSMY6NrSm2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file(fname='flower_photos', origin=dataset_url, untar=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "metadata": {
        "id": "Oz2k8Oun8bp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data exploration"
      ],
      "metadata": {
        "id": "fyz3WWVo8haT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset should contain around 3,700 photos of flowers, split into five sub-directories one for each class (daisy, dandelion, roses, sunflowers, tulips)."
      ],
      "metadata": {
        "id": "flXNKO7P8l7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the total number of images in the dataset."
      ],
      "metadata": {
        "id": "SZZR4jNF9Bjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "metadata": {
        "id": "8fHHEpwJ88ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check each sub-directory."
      ],
      "metadata": {
        "id": "IKhYe0s3X1l8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name in os.listdir('/root/.keras/datasets/flower_photos/'):\n",
        "  if (name!='LICENSE.txt'):\n",
        "    print(name)"
      ],
      "metadata": {
        "id": "QfpeGsg6YFKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the number of images in each sub-directory."
      ],
      "metadata": {
        "id": "joEG3EoVCa3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/root/.keras/datasets/flower_photos/dandelion')))"
      ],
      "metadata": {
        "id": "0paVGT5JCdy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/root/.keras/datasets/flower_photos/daisy')))"
      ],
      "metadata": {
        "id": "q1Kyn36M3Qnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/root/.keras/datasets/flower_photos/sunflowers')))"
      ],
      "metadata": {
        "id": "A7V-0VKoCl1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/root/.keras/datasets/flower_photos/roses')))"
      ],
      "metadata": {
        "id": "iWsVMdpbCot3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/root/.keras/datasets/flower_photos/tulips')))"
      ],
      "metadata": {
        "id": "oy3eodbjCr8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us visualize this as a bar chart."
      ],
      "metadata": {
        "id": "tnKdLDUMH8uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "flowers = ['dandelion', 'daisy', 'sunflowers', 'roses', 'tulips']\n",
        "n = [898, 633, 699, 641, 799]\n",
        "plt.bar(flowers, n, color=['yellow','gold','darkorange','red','orchid'])\n",
        "plt.xlabel('Class', fontsize=12)\n",
        "plt.ylabel('# of images', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AVjVnzQKEUb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the first few images in the daisy sub-directory."
      ],
      "metadata": {
        "id": "pRVpVLtK9P6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daisy = list(data_dir.glob('daisy/*'))\n",
        "PIL.Image.open(str(daisy[0]))"
      ],
      "metadata": {
        "id": "QmEaWQK39MxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PIL.Image.open(str(daisy[1]))"
      ],
      "metadata": {
        "id": "j-8YQTSI9baw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "amkOTCA39jiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to go from a directory of images on disk to a dataset. We will go this using the `tf.keras.utils.image_dataset_from_directory` utility."
      ],
      "metadata": {
        "id": "Pd3QD_E39niw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a dataset"
      ],
      "metadata": {
        "id": "02TCk2Ba-jHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, define parameters for the loader."
      ],
      "metadata": {
        "id": "cLcPg8ZWnaoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "id": "U51du7R0-lpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using a 80/20 validation split, so 80% of the images will be used for training and 20% will be used for validation."
      ],
      "metadata": {
        "id": "yZQGkFarnfMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the training dataset."
      ],
      "metadata": {
        "id": "uDwE-rqnZAyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "9XodHTMy-tJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the validation dataset."
      ],
      "metadata": {
        "id": "Pd-F3FgkZDRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "O7trfgPa--GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find the class names using the `class_names` attribute."
      ],
      "metadata": {
        "id": "L5pSXqCAnOuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "56zG0REH_DCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the dimensions of the image_batch tensor and the labels_batch tensor."
      ],
      "metadata": {
        "id": "RGdfO5C3ny9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "1y2Hq8fZfkaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure dataset for performace"
      ],
      "metadata": {
        "id": "JDfZOePDu3D8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "0X73omvMBNt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Turn off warnings - the Keras preprocessing layers can be very slow leading to warnings."
      ],
      "metadata": {
        "id": "UL7kojUAZq8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "id": "78O4q7ar75Pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data standardization"
      ],
      "metadata": {
        "id": "FD7kIulfVB8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RGB channel values are in the `[0, 255]` range, which is not ideal for a neural network. So we will standardize the input values to be in the `[0, 1]` range by defining a normalization layer and including it in the model definition."
      ],
      "metadata": {
        "id": "PWXeW7xhVGru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ],
      "metadata": {
        "id": "pGvS2uozViPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data visualization"
      ],
      "metadata": {
        "id": "9gW396l_vSSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the first nine images from the training set along with their true labels."
      ],
      "metadata": {
        "id": "fbXxlpk2oDwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch, label_batch = next(iter(train_ds))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "  label = label_batch[i]\n",
        "  plt.title(class_names[label],fontsize=18)\n",
        "  plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "XCC4NOkTvWei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overfitting"
      ],
      "metadata": {
        "id": "cabecbUHWc9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to reduce the effect of overfitting in the training process, we will implement data augmentation and the dropout technique."
      ],
      "metadata": {
        "id": "GOExI_jVWqCI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data augmentation"
      ],
      "metadata": {
        "id": "tvMhjFUAjMzZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation is the process of generating additional training data from the existing examples by augmenting the images using random transformations."
      ],
      "metadata": {
        "id": "DNYASr5ZjPaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use Keras preprocessing layers to implement data augmentation."
      ],
      "metadata": {
        "id": "Qblo3wK4aRkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\", input_shape=(img_height, img_width, 3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "O4tnV-bFjgWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize a few augmented examples by applying data augmentation to the same image several times."
      ],
      "metadata": {
        "id": "2gIM2P0wjxmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[4].numpy().astype(\"uint8\"))\n",
        "    plt.grid()"
      ],
      "metadata": {
        "id": "8-B08bi2kCAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropout"
      ],
      "metadata": {
        "id": "iHZbFOy2kLhC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another technique which can be used to reduce overfitting is dropout regularization. When we apply droput to a layer, it randomly drops out (by setting the activation to zero) a number of output units from the layer during the training process."
      ],
      "metadata": {
        "id": "N6xggCbqkSnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropout_layer = layers.Dropout(0.2)"
      ],
      "metadata": {
        "id": "ndFxuc7oXEUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model definition"
      ],
      "metadata": {
        "id": "cHmBMTH0B8wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will define a basic 5 layer CNN model below with three convolution layers (each followed by a ReLU and max-pooling layer) and two fully-connected layers."
      ],
      "metadata": {
        "id": "Y2bJyFtTXtoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255),\n",
        "\n",
        "  layers.Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "  layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
        "\n",
        "  layers.Conv2D(filters=96, kernel_size=(3,3), padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
        "\n",
        "  layers.Conv2D(filters=96, kernel_size=(3,3), padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
        "  \n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(512, activation='relu'),\n",
        "  layers.Dense(num_classes, name=\"outputs\")\n",
        "])"
      ],
      "metadata": {
        "id": "iUPyV63Zk5go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model compilation and training"
      ],
      "metadata": {
        "id": "aJw7Ygo_lKcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the `tf.keras.optimizers.Adam` optimizer and `tf.keras.losses.SparseCategoricalCrossentropy` loss function."
      ],
      "metadata": {
        "id": "ByJpEb6ACyEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "H17TaKW7lN-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the model summary."
      ],
      "metadata": {
        "id": "38iT4wPTbC_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "VD0Q5o-ZlSDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are ready to train the model now for 50 epochs (iterations)."
      ],
      "metadata": {
        "id": "7zbtip92bFf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "Vb7o798ulT1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating model performance"
      ],
      "metadata": {
        "id": "VXxem_yHlWsr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot training/validation set accuracy and loss."
      ],
      "metadata": {
        "id": "uYDUdwXqbjYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ],
      "metadata": {
        "id": "nLz78IIlbJAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_range = range(epochs)\n",
        "\n",
        "f = plt.figure(figsize=(16, 8))\n",
        "matplotlib.rcParams['font.family'] = \"sans-serif\"\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='training set', color='tab:purple')\n",
        "plt.plot(epochs_range, val_acc, label='validation set', color='tab:blue')\n",
        "plt.locator_params(axis=\"x\", integer=True, tight=True)\n",
        "plt.legend(loc='lower right', prop={'size': 18})\n",
        "plt.xlim([1, 50])\n",
        "plt.xlabel('Epoch #',fontsize=18)\n",
        "plt.ylabel('Accuracy',fontsize=18)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='training set', color='tab:purple')\n",
        "plt.plot(epochs_range, val_loss, label='validation set', color='tab:blue')\n",
        "plt.locator_params(axis=\"x\", integer=True, tight=True)\n",
        "plt.xlim([1, 50])\n",
        "\n",
        "plt.xlabel('Epoch #',fontsize=18)\n",
        "plt.ylabel('Loss',fontsize=18)\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xWdPIcOslgxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing predictions"
      ],
      "metadata": {
        "id": "W5jDqVgBb5Pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us have a look at the first nine images in the validation set and compare their actual labels to the label predicted by the model."
      ],
      "metadata": {
        "id": "KzwDsa6ob8g8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for images, labels in val_ds.take(1):\n",
        "\n",
        "  predictions = model.predict(images)\n",
        "\n",
        "  for i in range(9):\n",
        "    label_true = class_names[labels[i]]\n",
        "\n",
        "    score = tf.nn.softmax(predictions[i])\n",
        "    label_pred = class_names[np.argmax(score)]\n",
        "\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(\"Actual: {} \\n Predicted: {}\".format(label_true, label_pred))\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "_WLCvC1ab6SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correctly classified images"
      ],
      "metadata": {
        "id": "0b8iz1AscNsa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us have a look at a few images which were correctly classified."
      ],
      "metadata": {
        "id": "zPvb48I0buYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "count = 0\n",
        "\n",
        "for images, labels in val_ds.take(1):\n",
        "\n",
        "  predictions = model.predict(images)\n",
        "\n",
        "  for i in range(len(predictions)):\n",
        "\n",
        "    label_true = class_names[labels[i]]\n",
        "    score = tf.nn.softmax(predictions[i])\n",
        "\n",
        "    label_pred = class_names[np.argmax(score)]\n",
        "\n",
        "    if(label_pred==label_true):\n",
        "      ax = plt.subplot(1, 3, count + 1)\n",
        "      plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "      plt.title(\"Actual: {} \\n Predict: {}\".format(label_true, label_pred))\n",
        "      plt.axis(\"off\")\n",
        "      plt.grid()\n",
        "      count += 1\n",
        "\n",
        "    if(count==3):\n",
        "      break"
      ],
      "metadata": {
        "id": "IN0cG4P7cOwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Misclassified Images"
      ],
      "metadata": {
        "id": "WHRyXDemcQj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let us have a look at a few misclassified images."
      ],
      "metadata": {
        "id": "JYuUJk2mcGfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "count = 0\n",
        "\n",
        "for images, labels in val_ds.take(1):\n",
        "\n",
        "  predictions = model.predict(images)\n",
        "\n",
        "  for i in range(len(predictions)):\n",
        "\n",
        "    label_true = class_names[labels[i]]\n",
        "    score = tf.nn.softmax(predictions[i])\n",
        "\n",
        "    label_pred = class_names[np.argmax(score)]\n",
        "\n",
        "    if(label_pred!=label_true):\n",
        "      ax = plt.subplot(1, 3, count + 1)\n",
        "      plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "      plt.title(\"Actual: {} \\n Predict: {}\".format(label_true, label_pred))\n",
        "      plt.grid()\n",
        "      plt.axis(\"off\")\n",
        "      count += 1\n",
        "\n",
        "    if(count==3):\n",
        "      break"
      ],
      "metadata": {
        "id": "9gLgJR6ZcTAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "VqYYHNPhcVFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrices are a great tool for the visualization of errors in classification problems. They encode the complete specification of misclassifications: the numbers of misclassified items\n",
        "for each pair (original class in which items should be classified,\n",
        "incorrect class in which items are misclassified)."
      ],
      "metadata": {
        "id": "q80Bj-sU2XIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = []\n",
        "pred_labels = []\n",
        "\n",
        "for images, labels in val_ds:\n",
        "\n",
        "  predictions = model.predict(images)\n",
        "\n",
        "  for i in range(len(predictions)):\n",
        "\n",
        "    label_true = class_names[labels[i]]\n",
        "    score = tf.nn.softmax(predictions[i])\n",
        "\n",
        "    label_pred = class_names[np.argmax(score)]\n",
        "\n",
        "    test_labels.append(label_true)\n",
        "    pred_labels.append(label_pred)"
      ],
      "metadata": {
        "id": "ggHiG4ZCcaSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tn_yEVw2cwgH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}